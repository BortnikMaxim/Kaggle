{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from textblob import Word\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/Users/maximbortnik/Downloads/archive/train.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29720</td>\n",
       "      <td>29720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  tweet\n",
       "label              \n",
       "0      29720  29720\n",
       "1       2242   2242"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks credit cant use cause dont offer wheelc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0   @user when a father is dysfunctional and is s...   \n",
       "1  @user @user thanks for #lyft credit i can't us...   \n",
       "2                                bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  father dysfunctional selfish drag kid dysfunction  \n",
       "1  thanks credit cant use cause dont offer wheelc...  \n",
       "2                                     bihday majesty  \n",
       "3                              love u take u time ur  \n",
       "4                                 factsguide society  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text_with_lemmatization(text):\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление упоминаний @user\n",
    "    text = re.sub(r'@\\w+', ' ', text)\n",
    "    # Удаление ссылок\n",
    "    text = re.sub(r'http\\S+|www.\\S+', ' ', text)\n",
    "    # Удаление хэштегов и других спецсимволов\n",
    "    text = re.sub(r'#\\w+', ' ', text)\n",
    "    # Удаление пунктуации и цифр\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Удаление лишних пробелов\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Удаление стоп-слов\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    text = \" \".join(word for word in text.split() if word not in sw)\n",
    "    # Лемматизация\n",
    "    text = \" \".join(Word(word).lemmatize() for word in text.split())\n",
    "    return text\n",
    "\n",
    "# Применение предобработки с лемматизацией к данным\n",
    "train_df['clean_tweet'] = train_df['tweet'].apply(preprocess_text_with_lemmatization)\n",
    "\n",
    "# Пример предобработанных данных\n",
    "train_df[['tweet', 'clean_tweet']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на X (признаки) и y (метки)\n",
    "X = train_df['clean_tweet']\n",
    "y = train_df['label']\n",
    "\n",
    "# Разделение данных на тренировочную и валидационную выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF векторизация\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)\n",
    "\n",
    "# CountVectorizer\n",
    "count_vec = CountVectorizer(ngram_range=(1, 2), max_features=10000)\n",
    "X_train_count = count_vec.fit_transform(X_train)\n",
    "X_val_count = count_vec.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      5945\n",
      "           1       0.99      0.20      0.34       448\n",
      "\n",
      "    accuracy                           0.94      6393\n",
      "   macro avg       0.97      0.60      0.65      6393\n",
      "weighted avg       0.95      0.94      0.93      6393\n",
      "\n",
      "Naive Bayes (CountVectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5945\n",
      "           1       0.65      0.46      0.53       448\n",
      "\n",
      "    accuracy                           0.94      6393\n",
      "   macro avg       0.80      0.72      0.75      6393\n",
      "weighted avg       0.94      0.94      0.94      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение на TF-IDF\n",
    "nb_model_tfidf = MultinomialNB()\n",
    "nb_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = nb_model_tfidf.predict(X_val_tfidf)\n",
    "\n",
    "print(\"Naive Bayes (TF-IDF):\")\n",
    "print(classification_report(y_val, y_pred_tfidf))\n",
    "\n",
    "# Обучение на CountVectorizer\n",
    "nb_model_count = MultinomialNB()\n",
    "nb_model_count.fit(X_train_count, y_train)\n",
    "y_pred_count = nb_model_count.predict(X_val_count)\n",
    "\n",
    "print(\"Naive Bayes (CountVectorizer):\")\n",
    "print(classification_report(y_val, y_pred_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes (TF-IDF) : Модель плохо справляется с классом 1, что видно по низкому Recall (0.20).\n",
    "\n",
    "Naive Bayes (CountVectorizer) : Recall и F1-score для класса 1 выше, чем с TF-IDF.(0.46)(0.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      5945\n",
      "           1       0.92      0.24      0.38       448\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.93      0.62      0.68      6393\n",
      "weighted avg       0.94      0.95      0.93      6393\n",
      "\n",
      "Logistic Regression (CountVectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5945\n",
      "           1       0.79      0.38      0.51       448\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.87      0.68      0.74      6393\n",
      "weighted avg       0.94      0.95      0.94      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression с TF-IDF\n",
    "log_model_tfidf = LogisticRegression(max_iter=1000)\n",
    "log_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_log_tfidf = log_model_tfidf.predict(X_val_tfidf)\n",
    "\n",
    "print(\"Logistic Regression (TF-IDF):\")\n",
    "print(classification_report(y_val, y_pred_log_tfidf))\n",
    "\n",
    "# Logistic Regression с CountVectorizer\n",
    "log_model_count = LogisticRegression(max_iter=1000)\n",
    "log_model_count.fit(X_train_count, y_train)\n",
    "y_pred_log_count = log_model_count.predict(X_val_count)\n",
    "\n",
    "print(\"Logistic Regression (CountVectorizer):\")\n",
    "print(classification_report(y_val, y_pred_log_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression (TF-IDF): Лог Регрессия улучшает Precision для класса 1 (0.92), но Recall остаётся низким(0.24).\n",
    "\n",
    "С CountVectorizer Logistic Regression показывает лучший Recall для класса 1, чем с TF-IDF(0.38)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5871100\ttotal: 40.3ms\tremaining: 40.2s\n",
      "200:\tlearn: 0.1616826\ttotal: 4.51s\tremaining: 17.9s\n",
      "400:\tlearn: 0.1363232\ttotal: 9.01s\tremaining: 13.5s\n",
      "600:\tlearn: 0.1237464\ttotal: 13.2s\tremaining: 8.78s\n",
      "800:\tlearn: 0.1128207\ttotal: 17.2s\tremaining: 4.27s\n",
      "999:\tlearn: 0.1023399\ttotal: 21.2s\tremaining: 0us\n",
      "CatBoost (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5945\n",
      "           1       0.81      0.36      0.50       448\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.88      0.68      0.74      6393\n",
      "weighted avg       0.94      0.95      0.94      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost с TF-IDF\n",
    "cat_model_tfidf = CatBoostClassifier(iterations=1000, learning_rate=0.1, verbose=200)\n",
    "cat_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_cat_tfidf = cat_model_tfidf.predict(X_val_tfidf)\n",
    "\n",
    "print(\"CatBoost (TF-IDF):\")\n",
    "print(classification_report(y_val, y_pred_cat_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost справляется с классом 1 лучше, чем Logistic Regression (TF-IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5900333\ttotal: 11.7ms\tremaining: 11.7s\n",
      "200:\tlearn: 0.1659951\ttotal: 2.43s\tremaining: 9.65s\n",
      "400:\tlearn: 0.1456997\ttotal: 4.74s\tremaining: 7.08s\n",
      "600:\tlearn: 0.1308068\ttotal: 7.07s\tremaining: 4.7s\n",
      "800:\tlearn: 0.1201064\ttotal: 9.4s\tremaining: 2.33s\n",
      "999:\tlearn: 0.1115098\ttotal: 11.7s\tremaining: 0us\n",
      "CatBoost (CountVectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      5945\n",
      "           1       0.85      0.35      0.50       448\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.90      0.68      0.74      6393\n",
      "weighted avg       0.95      0.95      0.94      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost с CountVectorizer\n",
    "cat_model_count = CatBoostClassifier(iterations=1000, learning_rate=0.1, verbose=200)\n",
    "cat_model_count.fit(X_train_count, y_train)\n",
    "y_pred_cat_count = cat_model_count.predict(X_val_count)\n",
    "\n",
    "print(\"CatBoost (CountVectorizer):\")\n",
    "print(classification_report(y_val, y_pred_cat_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты с CountVectorizer почти аналогичны TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Применем SMOTE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс после SMOTE: label\n",
      "0    23775\n",
      "1    23775\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Применение SMOTE к данным\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Проверка баланса\n",
    "print(\"Баланс после SMOTE:\", y_train_balanced.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6638931\ttotal: 37.7ms\tremaining: 1m 15s\n",
      "200:\tlearn: 0.2977111\ttotal: 6.36s\tremaining: 56.9s\n",
      "400:\tlearn: 0.2491959\ttotal: 12.6s\tremaining: 50.4s\n",
      "600:\tlearn: 0.2211494\ttotal: 19s\tremaining: 44.2s\n",
      "800:\tlearn: 0.2025838\ttotal: 25.6s\tremaining: 38.3s\n",
      "1000:\tlearn: 0.1885995\ttotal: 32.1s\tremaining: 32s\n",
      "1200:\tlearn: 0.1783017\ttotal: 38.3s\tremaining: 25.5s\n",
      "1400:\tlearn: 0.1699239\ttotal: 44.6s\tremaining: 19.1s\n",
      "1600:\tlearn: 0.1627221\ttotal: 50.8s\tremaining: 12.7s\n",
      "1800:\tlearn: 0.1565859\ttotal: 57s\tremaining: 6.3s\n",
      "1999:\tlearn: 0.1509805\ttotal: 1m 3s\tremaining: 0us\n",
      "CatBoost (с балансировкой):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.82      5945\n",
      "           1       0.17      0.79      0.28       448\n",
      "\n",
      "    accuracy                           0.71      6393\n",
      "   macro avg       0.57      0.75      0.55      6393\n",
      "weighted avg       0.92      0.71      0.78      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# CatBoost с балансировкой\n",
    "cat_model_balanced = CatBoostClassifier(\n",
    "    iterations=2000,  \n",
    "    learning_rate=0.05,  \n",
    "    depth=6,  \n",
    "    l2_leaf_reg=3,  \n",
    "    class_weights=[1, 5], \n",
    "    verbose=200\n",
    ")\n",
    "cat_model_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_pred_cat_balanced = cat_model_balanced.predict(X_val_tfidf)\n",
    "\n",
    "print(\"CatBoost (с балансировкой):\")\n",
    "print(classification_report(y_val, y_pred_cat_balanced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Балансировка значительно увеличивает Recall для класса 1, но снижает Precision для класса 0, что приводит к снижению Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (TF-IDF + TruncatedSVD):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      5945\n",
      "           1       0.82      0.18      0.30       448\n",
      "\n",
      "    accuracy                           0.94      6393\n",
      "   macro avg       0.88      0.59      0.63      6393\n",
      "weighted avg       0.93      0.94      0.92      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X = train_df['clean_tweet'] \n",
    "y = train_df['label']        \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF \n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)\n",
    "\n",
    "# TruncatedSVD для снижения размерности\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_val_svd = svd.transform(X_val_tfidf)\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000, solver='saga', random_state=42)\n",
    "log_model.fit(X_train_svd, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_val_svd)\n",
    "\n",
    "print(\"Logistic Regression (TF-IDF + TruncatedSVD):\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TruncatedSVD уменьшает размерность данных, но результаты для класса 1 становятся хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**:\n",
    "1) *Naive Bayes*:\n",
    "Хорошо справляется с классом 0, но имеет низкий Recall для класса 1.\n",
    "2) *Logistic Regression*:\n",
    "Обеспечивает более высокий F1-Score для класса 1, чем Naive Bayes, особенно с CountVectorizer.\n",
    "3) *CatBoost*:\n",
    "Показал лучшие результаты для F1-Score класса 1 (0.50) без балансировки.\n",
    "Балансировка классов значительно увеличила Recall для класса 1 (до 0.79), но снизила точность предсказаний для класса 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
